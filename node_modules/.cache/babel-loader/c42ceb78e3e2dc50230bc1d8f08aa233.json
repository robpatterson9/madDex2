{"ast":null,"code":"import _regeneratorRuntime from\"/Volumes/evo970/lou/madDex-master/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";import _asyncToGenerator from\"/Volumes/evo970/lou/madDex-master/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";import _slicedToArray from\"/Volumes/evo970/lou/madDex-master/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";import _toConsumableArray from\"/Volumes/evo970/lou/madDex-master/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/toConsumableArray\";import _taggedTemplateLiteral from\"/Volumes/evo970/lou/madDex-master/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/taggedTemplateLiteral\";var _templateObject,_templateObject2;import{useState,useEffect}from'react';import{request,gql}from'graphql-request';import{INFO_CLIENT}from'config/constants/endpoints';import{useTokenDatas,usePoolDatas}from'state/info/hooks';import{MINIMUM_SEARCH_CHARACTERS}from'config/constants/info';var TOKEN_SEARCH=gql(_templateObject||(_templateObject=_taggedTemplateLiteral([\"\\n  query tokens($symbol: String, $name: String, $id: String) {\\n    asSymbol: tokens(first: 10, where: { symbol_contains: $symbol }, orderBy: tradeVolumeUSD, orderDirection: desc) {\\n      id\\n    }\\n    asName: tokens(first: 10, where: { name_contains: $name }, orderBy: tradeVolumeUSD, orderDirection: desc) {\\n      id\\n    }\\n    asAddress: tokens(first: 1, where: { id: $id }, orderBy: tradeVolumeUSD, orderDirection: desc) {\\n      id\\n    }\\n  }\\n\"])));var POOL_SEARCH=gql(_templateObject2||(_templateObject2=_taggedTemplateLiteral([\"\\n  query pools($tokens: [Bytes]!, $id: String) {\\n    as0: pairs(first: 10, where: { token0_in: $tokens }) {\\n      id\\n    }\\n    as1: pairs(first: 10, where: { token1_in: $tokens }) {\\n      id\\n    }\\n    asAddress: pairs(first: 1, where: { id: $id }) {\\n      id\\n    }\\n  }\\n\"])));var getIds=function getIds(entityArrays){var ids=entityArrays.reduce(function(entities,currentTokenArray){return[].concat(_toConsumableArray(entities),_toConsumableArray(currentTokenArray));},[]).map(function(entity){return entity.id;});return Array.from(new Set(ids));};var useFetchSearchResults=function useFetchSearchResults(searchString){var _useState=useState({tokens:[],// Token ids found by search query\npools:[],// Pool ids found by search query\nloading:false,// Search query is in progress\nerror:false// GraphQL returned error\n}),_useState2=_slicedToArray(_useState,2),searchResults=_useState2[0],setSearchResults=_useState2[1];var searchStringTooShort=searchString.length<MINIMUM_SEARCH_CHARACTERS;// New value received, reset state\nuseEffect(function(){setSearchResults({tokens:[],pools:[],loading:!searchStringTooShort,error:false});},[searchString,searchStringTooShort]);useEffect(function(){var search=/*#__PURE__*/function(){var _ref=_asyncToGenerator(/*#__PURE__*/_regeneratorRuntime.mark(function _callee(){var tokens,tokenIds,pools;return _regeneratorRuntime.wrap(function _callee$(_context){while(1){switch(_context.prev=_context.next){case 0:_context.prev=0;_context.next=3;return request(INFO_CLIENT,TOKEN_SEARCH,{symbol:searchString.toUpperCase(),// Most well known tokens have first letter capitalized\nname:searchString.charAt(0).toUpperCase()+searchString.slice(1),id:searchString.toLowerCase()});case 3:tokens=_context.sent;tokenIds=getIds([tokens.asAddress,tokens.asSymbol,tokens.asName]);_context.next=7;return request(INFO_CLIENT,POOL_SEARCH,{tokens:tokenIds,id:searchString.toLowerCase()});case 7:pools=_context.sent;setSearchResults({tokens:tokenIds,pools:getIds([pools.asAddress,pools.as0,pools.as1]),loading:false,error:false});_context.next=15;break;case 11:_context.prev=11;_context.t0=_context[\"catch\"](0);console.error(\"Search failed for \".concat(searchString),_context.t0);setSearchResults({tokens:[],pools:[],loading:false,error:true});case 15:case\"end\":return _context.stop();}}},_callee,null,[[0,11]]);}));return function search(){return _ref.apply(this,arguments);};}();if(!searchStringTooShort){search();}},[searchString,searchStringTooShort]);// Save ids to Redux\n// Token and Pool updater will then go fetch full data for these addresses\n// These hooks in turn will return data of tokens that have been fetched\nvar tokenDatasFull=useTokenDatas(searchResults.tokens);var poolDatasFull=usePoolDatas(searchResults.pools);// If above hooks returned not all tokens/pools it means\n// that some requests for full data are in progress\nvar tokensLoading=tokenDatasFull.length!==searchResults.tokens.length||searchResults.loading;var poolsLoading=poolDatasFull.length!==searchResults.pools.length||searchResults.loading;return{tokens:tokenDatasFull,pools:poolDatasFull,tokensLoading:tokensLoading,poolsLoading:poolsLoading,error:searchResults.error};};export default useFetchSearchResults;","map":{"version":3,"sources":["/Volumes/evo970/lou/madDex-master/src/state/info/queries/search/index.ts"],"names":["useState","useEffect","request","gql","INFO_CLIENT","useTokenDatas","usePoolDatas","MINIMUM_SEARCH_CHARACTERS","TOKEN_SEARCH","POOL_SEARCH","getIds","entityArrays","ids","reduce","entities","currentTokenArray","map","entity","id","Array","from","Set","useFetchSearchResults","searchString","tokens","pools","loading","error","searchResults","setSearchResults","searchStringTooShort","length","search","symbol","toUpperCase","name","charAt","slice","toLowerCase","tokenIds","asAddress","asSymbol","asName","as0","as1","console","tokenDatasFull","poolDatasFull","tokensLoading","poolsLoading"],"mappings":"kzBAAA,OAASA,QAAT,CAAmBC,SAAnB,KAAoC,OAApC,CACA,OAASC,OAAT,CAAkBC,GAAlB,KAA6B,iBAA7B,CACA,OAASC,WAAT,KAA4B,4BAA5B,CACA,OAASC,aAAT,CAAwBC,YAAxB,KAA4C,kBAA5C,CAEA,OAASC,yBAAT,KAA0C,uBAA1C,CAEA,GAAMC,CAAAA,YAAY,CAAGL,GAAH,wgBAAlB,CAcA,GAAMM,CAAAA,WAAW,CAAGN,GAAH,4VAAjB,CA6BA,GAAMO,CAAAA,MAAM,CAAG,QAATA,CAAAA,MAAS,CAACC,YAAD,CAA2C,CACxD,GAAMC,CAAAA,GAAG,CAAGD,YAAY,CACrBE,MADS,CACF,SAACC,QAAD,CAAWC,iBAAX,qCAAqCD,QAArC,qBAAkDC,iBAAlD,IADE,CACoE,EADpE,EAETC,GAFS,CAEL,SAACC,MAAD,QAAYA,CAAAA,MAAM,CAACC,EAAnB,EAFK,CAAZ,CAGA,MAAOC,CAAAA,KAAK,CAACC,IAAN,CAAW,GAAIC,CAAAA,GAAJ,CAAQT,GAAR,CAAX,CAAP,CACD,CALD,CAOA,GAAMU,CAAAA,qBAAqB,CAAG,QAAxBA,CAAAA,qBAAwB,CAC5BC,YAD4B,CAQzB,CACH,cAA0CvB,QAAQ,CAAC,CACjDwB,MAAM,CAAE,EADyC,CACrC;AACZC,KAAK,CAAE,EAF0C,CAEtC;AACXC,OAAO,CAAE,KAHwC,CAGjC;AAChBC,KAAK,CAAE,KAAO;AAJmC,CAAD,CAAlD,wCAAOC,aAAP,eAAsBC,gBAAtB,eAOA,GAAMC,CAAAA,oBAAoB,CAAGP,YAAY,CAACQ,MAAb,CAAsBxB,yBAAnD,CAEA;AACAN,SAAS,CAAC,UAAM,CACd4B,gBAAgB,CAAC,CACfL,MAAM,CAAE,EADO,CAEfC,KAAK,CAAE,EAFQ,CAGfC,OAAO,CAAE,CAACI,oBAHK,CAIfH,KAAK,CAAE,KAJQ,CAAD,CAAhB,CAMD,CAPQ,CAON,CAACJ,YAAD,CAAeO,oBAAf,CAPM,CAAT,CASA7B,SAAS,CAAC,UAAM,CACd,GAAM+B,CAAAA,MAAM,0FAAG,mMAEU9B,CAAAA,OAAO,CAAsBE,WAAtB,CAAmCI,YAAnC,CAAiD,CAC3EyB,MAAM,CAAEV,YAAY,CAACW,WAAb,EADmE,CAE3E;AACAC,IAAI,CAAEZ,YAAY,CAACa,MAAb,CAAoB,CAApB,EAAuBF,WAAvB,GAAuCX,YAAY,CAACc,KAAb,CAAmB,CAAnB,CAH8B,CAI3EnB,EAAE,CAAEK,YAAY,CAACe,WAAb,EAJuE,CAAjD,CAFjB,QAELd,MAFK,eAQLe,QARK,CAQM7B,MAAM,CAAC,CAACc,MAAM,CAACgB,SAAR,CAAmBhB,MAAM,CAACiB,QAA1B,CAAoCjB,MAAM,CAACkB,MAA3C,CAAD,CARZ,uBASSxC,CAAAA,OAAO,CAAqBE,WAArB,CAAkCK,WAAlC,CAA+C,CACxEe,MAAM,CAAEe,QADgE,CAExErB,EAAE,CAAEK,YAAY,CAACe,WAAb,EAFoE,CAA/C,CAThB,QASLb,KATK,eAaXI,gBAAgB,CAAC,CACfL,MAAM,CAAEe,QADO,CAEfd,KAAK,CAAEf,MAAM,CAAC,CAACe,KAAK,CAACe,SAAP,CAAkBf,KAAK,CAACkB,GAAxB,CAA6BlB,KAAK,CAACmB,GAAnC,CAAD,CAFE,CAGflB,OAAO,CAAE,KAHM,CAIfC,KAAK,CAAE,KAJQ,CAAD,CAAhB,CAbW,iFAoBXkB,OAAO,CAAClB,KAAR,6BAAmCJ,YAAnC,eACAM,gBAAgB,CAAC,CACfL,MAAM,CAAE,EADO,CAEfC,KAAK,CAAE,EAFQ,CAGfC,OAAO,CAAE,KAHM,CAIfC,KAAK,CAAE,IAJQ,CAAD,CAAhB,CArBW,qEAAH,kBAANK,CAAAA,MAAM,0CAAZ,CA6BA,GAAI,CAACF,oBAAL,CAA2B,CACzBE,MAAM,GACP,CACF,CAjCQ,CAiCN,CAACT,YAAD,CAAeO,oBAAf,CAjCM,CAAT,CAmCA;AACA;AACA;AACA,GAAMgB,CAAAA,cAAc,CAAGzC,aAAa,CAACuB,aAAa,CAACJ,MAAf,CAApC,CACA,GAAMuB,CAAAA,aAAa,CAAGzC,YAAY,CAACsB,aAAa,CAACH,KAAf,CAAlC,CAEA;AACA;AACA,GAAMuB,CAAAA,aAAa,CAAGF,cAAc,CAACf,MAAf,GAA0BH,aAAa,CAACJ,MAAd,CAAqBO,MAA/C,EAAyDH,aAAa,CAACF,OAA7F,CACA,GAAMuB,CAAAA,YAAY,CAAGF,aAAa,CAAChB,MAAd,GAAyBH,aAAa,CAACH,KAAd,CAAoBM,MAA7C,EAAuDH,aAAa,CAACF,OAA1F,CAEA,MAAO,CACLF,MAAM,CAAEsB,cADH,CAELrB,KAAK,CAAEsB,aAFF,CAGLC,aAAa,CAAbA,aAHK,CAILC,YAAY,CAAZA,YAJK,CAKLtB,KAAK,CAAEC,aAAa,CAACD,KALhB,CAAP,CAOD,CAjFD,CAmFA,cAAeL,CAAAA,qBAAf","sourcesContent":["import { useState, useEffect } from 'react'\nimport { request, gql } from 'graphql-request'\nimport { INFO_CLIENT } from 'config/constants/endpoints'\nimport { useTokenDatas, usePoolDatas } from 'state/info/hooks'\nimport { TokenData, PoolData } from 'state/info/types'\nimport { MINIMUM_SEARCH_CHARACTERS } from 'config/constants/info'\n\nconst TOKEN_SEARCH = gql`\n  query tokens($symbol: String, $name: String, $id: String) {\n    asSymbol: tokens(first: 10, where: { symbol_contains: $symbol }, orderBy: tradeVolumeUSD, orderDirection: desc) {\n      id\n    }\n    asName: tokens(first: 10, where: { name_contains: $name }, orderBy: tradeVolumeUSD, orderDirection: desc) {\n      id\n    }\n    asAddress: tokens(first: 1, where: { id: $id }, orderBy: tradeVolumeUSD, orderDirection: desc) {\n      id\n    }\n  }\n`\n\nconst POOL_SEARCH = gql`\n  query pools($tokens: [Bytes]!, $id: String) {\n    as0: pairs(first: 10, where: { token0_in: $tokens }) {\n      id\n    }\n    as1: pairs(first: 10, where: { token1_in: $tokens }) {\n      id\n    }\n    asAddress: pairs(first: 1, where: { id: $id }) {\n      id\n    }\n  }\n`\n\ninterface SingleQueryResponse {\n  id: string[]\n}\n\ninterface TokenSearchResponse {\n  asSymbol: SingleQueryResponse[]\n  asName: SingleQueryResponse[]\n  asAddress: SingleQueryResponse[]\n}\ninterface PoolSearchResponse {\n  as0: SingleQueryResponse[]\n  as1: SingleQueryResponse[]\n  asAddress: SingleQueryResponse[]\n}\n\nconst getIds = (entityArrays: SingleQueryResponse[][]) => {\n  const ids = entityArrays\n    .reduce((entities, currentTokenArray) => [...entities, ...currentTokenArray], [])\n    .map((entity) => entity.id)\n  return Array.from(new Set(ids))\n}\n\nconst useFetchSearchResults = (\n  searchString: string,\n): {\n  tokens: TokenData[]\n  pools: PoolData[]\n  tokensLoading: boolean\n  poolsLoading: boolean\n  error: boolean\n} => {\n  const [searchResults, setSearchResults] = useState({\n    tokens: [], // Token ids found by search query\n    pools: [], // Pool ids found by search query\n    loading: false, // Search query is in progress\n    error: false, // GraphQL returned error\n  })\n\n  const searchStringTooShort = searchString.length < MINIMUM_SEARCH_CHARACTERS\n\n  // New value received, reset state\n  useEffect(() => {\n    setSearchResults({\n      tokens: [],\n      pools: [],\n      loading: !searchStringTooShort,\n      error: false,\n    })\n  }, [searchString, searchStringTooShort])\n\n  useEffect(() => {\n    const search = async () => {\n      try {\n        const tokens = await request<TokenSearchResponse>(INFO_CLIENT, TOKEN_SEARCH, {\n          symbol: searchString.toUpperCase(),\n          // Most well known tokens have first letter capitalized\n          name: searchString.charAt(0).toUpperCase() + searchString.slice(1),\n          id: searchString.toLowerCase(),\n        })\n        const tokenIds = getIds([tokens.asAddress, tokens.asSymbol, tokens.asName])\n        const pools = await request<PoolSearchResponse>(INFO_CLIENT, POOL_SEARCH, {\n          tokens: tokenIds,\n          id: searchString.toLowerCase(),\n        })\n        setSearchResults({\n          tokens: tokenIds,\n          pools: getIds([pools.asAddress, pools.as0, pools.as1]),\n          loading: false,\n          error: false,\n        })\n      } catch (error) {\n        console.error(`Search failed for ${searchString}`, error)\n        setSearchResults({\n          tokens: [],\n          pools: [],\n          loading: false,\n          error: true,\n        })\n      }\n    }\n    if (!searchStringTooShort) {\n      search()\n    }\n  }, [searchString, searchStringTooShort])\n\n  // Save ids to Redux\n  // Token and Pool updater will then go fetch full data for these addresses\n  // These hooks in turn will return data of tokens that have been fetched\n  const tokenDatasFull = useTokenDatas(searchResults.tokens)\n  const poolDatasFull = usePoolDatas(searchResults.pools)\n\n  // If above hooks returned not all tokens/pools it means\n  // that some requests for full data are in progress\n  const tokensLoading = tokenDatasFull.length !== searchResults.tokens.length || searchResults.loading\n  const poolsLoading = poolDatasFull.length !== searchResults.pools.length || searchResults.loading\n\n  return {\n    tokens: tokenDatasFull,\n    pools: poolDatasFull,\n    tokensLoading,\n    poolsLoading,\n    error: searchResults.error,\n  }\n}\n\nexport default useFetchSearchResults\n"]},"metadata":{},"sourceType":"module"}